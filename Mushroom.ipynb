{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUSHROOM\n",
    "### Source:\n",
    "https://archive.ics.uci.edu/ml/datasets/mushroom\n",
    "### Goal:\n",
    "Predict whether or not a mushroom is edible or not based off 22 different categorical characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests, zipfile, io\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, roc_auc_score, roc_curve, make_scorer\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo 1: LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_classifier(X_train, Y_train, X_test, Y_test):\n",
    "    # define hyperparameters to search through & error metrics \n",
    "    C_list = [10**-8,10**-7,10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3,10**4]\n",
    "    penalty_list = ['l2', 'l1', 'none']\n",
    "    solver = ['saga'] #this solver works for no penalty, l1 and l2 penalties\n",
    "    scoring = {'Accuracy': make_scorer(accuracy_score), 'f1': 'f1', 'AUC': 'roc_auc'}\n",
    "    classifier = LogisticRegression()\n",
    "        \n",
    "    # gridsearch \n",
    "    lr =  GridSearchCV(classifier, {'C':C_list, 'penalty':penalty_list,'solver':solver},\n",
    "                                   scoring=scoring,refit=False, cv=5, n_jobs=-1, \n",
    "                                   return_train_score=True, verbose=2 ) \n",
    "        \n",
    "    lr.fit(X_train,Y_train)\n",
    "    results = pd.DataFrame(lr.cv_results_)\n",
    "        \n",
    "    # Get each parameter settings that gives best accuracy, F1, and AUC on validation set\n",
    "    best_AUC = results[results['rank_test_AUC']==1]['params'].values[0]\n",
    "    best_accuracy = results[results['rank_test_Accuracy']  ==1]['params'].values[0]\n",
    "    best_F1 = results[results['rank_test_f1']  ==1]['params'].values[0]\n",
    "        \n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    clf_AUC = LogisticRegression(C=best_AUC['C'], solver = best_AUC['solver'],\n",
    "                             penalty=best_AUC['penalty']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_accuracy = LogisticRegression(C=best_accuracy['C'], solver = best_accuracy['solver'],\n",
    "                             penalty=best_accuracy['penalty']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_F1 = LogisticRegression(C=best_F1['C'], solver = best_F1['solver'],\n",
    "                                penalty=best_F1['penalty']).fit(X_train, Y_train)\n",
    "        \n",
    "    # For average training performance\n",
    "    train_accuracy = clf_accuracy.score(X_train, Y_train)  # Accuracy  \n",
    "    train_F1 = f1_score(Y_train, clf_F1.predict(X_train))   # F1\n",
    "    fpr, tpr, threshold = roc_curve(Y_train, clf_AUC.predict_proba(X_train)[:,1])\n",
    "    train_auc = auc(fpr, tpr) # AUC\n",
    "        \n",
    "    # Find and store accuracy, F1, and AUC of the 3 models from previous line on test set\n",
    "    test_accuracy = clf_accuracy.score(X_test, Y_test)  # Accuracy\n",
    "    \n",
    "    test_F1 = f1_score(Y_test, clf_F1.predict(X_test))   # F1\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, clf_AUC.predict_proba(X_test)[:,1])\n",
    "    test_auc = auc(false_positive_rate, true_positive_rate) # AUC\n",
    "\n",
    "    return train_accuracy, train_F1, train_auc, test_accuracy, test_F1, test_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo 2: RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classifier(X_train,Y_train,X_test,Y_test):\n",
    "    # define hyperparameters to search through & error metrics  \n",
    "    n_estimators = [1024]\n",
    "    min_samples_split = [1,2,4,6,8,12,16,20]\n",
    "    scoring = {'Accuracy': make_scorer(accuracy_score), 'f1': 'f1', 'AUC': 'roc_auc'}\n",
    "    classifier = RandomForestClassifier()\n",
    "\n",
    "    rf =  GridSearchCV(classifier, {'n_estimators':n_estimators, 'min_samples_split':min_samples_split},\n",
    "                                   scoring=scoring,refit=False, cv=5, n_jobs=-1, \n",
    "                                   return_train_score=True, verbose=2) \n",
    "\n",
    "    rf.fit(X_train,Y_train)\n",
    "    results = pd.DataFrame(rf.cv_results_)\n",
    "        \n",
    "    # Get each parameter settings that gives best accuracy, F1, and AUC on validation set\n",
    "    best_AUC = results[results['rank_test_AUC']==1]['params'].values[0]\n",
    "    best_accuracy = results[results['rank_test_Accuracy']  ==1]['params'].values[0]\n",
    "    best_F1 = results[results['rank_test_f1']  ==1]['params'].values[0]\n",
    "\n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    clf_AUC = RandomForestClassifier(n_estimators=best_AUC['n_estimators'], \n",
    "                              min_samples_split=best_AUC['min_samples_split']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_accuracy = RandomForestClassifier(n_estimators=best_accuracy['n_estimators'], \n",
    "                              min_samples_split=best_accuracy['min_samples_split']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_F1 = RandomForestClassifier(n_estimators=best_F1['n_estimators'], \n",
    "                                  min_samples_split=best_F1['min_samples_split']).fit(X_train, Y_train)\n",
    "\n",
    "    # For average training performance\n",
    "    train_accuracy = clf_accuracy.score(X_train, Y_train)  # Accuracy  \n",
    "    train_F1 = f1_score(Y_train, clf_F1.predict(X_train))   # F1\n",
    "    fpr, tpr, threshold = roc_curve(Y_train, clf_AUC.predict_proba(X_train)[:,1])\n",
    "    train_auc = auc(fpr, tpr) # AUC\n",
    "        \n",
    "    # Find and store accuracy, F1, and AUC of the 3 models from previous line on test set\n",
    "    test_accuracy = clf_accuracy.score(X_test, Y_test)  # Accuracy\n",
    "    \n",
    "    test_F1 = f1_score(Y_test, clf_F1.predict(X_test))   # F1\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, clf_AUC.predict_proba(X_test)[:,1])\n",
    "    test_auc = auc(false_positive_rate, true_positive_rate) # AUC\n",
    "\n",
    "    return train_accuracy, train_F1, train_auc, test_accuracy, test_F1, test_auc\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo 3: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(X_train,Y_train,X_test,Y_test):\n",
    "    # define hyperparameters to search through & error metrics  \n",
    "    n_neighbors = np.linspace(1, 105, num=27, dtype=int)\n",
    "    weights = ['uniform', 'distance']\n",
    "    p = [1,2]\n",
    "    scoring = {'Accuracy': make_scorer(accuracy_score), 'f1': 'f1', 'AUC': 'roc_auc'}\n",
    "    classifier = KNeighborsClassifier()\n",
    "\n",
    "    rf =  GridSearchCV(classifier, {'n_neighbors':n_neighbors, 'weights': weights, 'p':p},\n",
    "                                   scoring=scoring,refit=False, cv=5, n_jobs=-1, \n",
    "                                   return_train_score=True, verbose=2) \n",
    "\n",
    "    rf.fit(X_train,Y_train)\n",
    "    results = pd.DataFrame(rf.cv_results_)\n",
    "        \n",
    "    # Get each parameter settings that gives best accuracy, F1, and AUC on validation set\n",
    "    best_AUC = results[results['rank_test_AUC']==1]['params'].values[0]\n",
    "    best_accuracy = results[results['rank_test_Accuracy']  ==1]['params'].values[0]\n",
    "    best_F1 = results[results['rank_test_f1']  ==1]['params'].values[0]\n",
    "\n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    clf_AUC = KNeighborsClassifier(n_neighbors=best_AUC['n_neighbors'], \n",
    "                             weights=best_AUC['weights'], p = best_AUC['p']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_accuracy = KNeighborsClassifier(n_neighbors=best_accuracy['n_neighbors'], \n",
    "                              weights=best_accuracy['weights']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_F1 = KNeighborsClassifier(n_neighbors=best_F1['n_neighbors'], \n",
    "                                  weights=best_F1['weights'], p = best_F1['p']).fit(X_train, Y_train)\n",
    "\n",
    "    # For average training performance\n",
    "    train_accuracy = clf_accuracy.score(X_train, Y_train)  # Accuracy  \n",
    "    train_F1 = f1_score(Y_train, clf_F1.predict(X_train))   # F1\n",
    "    fpr, tpr, threshold = roc_curve(Y_train, clf_AUC.predict_proba(X_train)[:,1])\n",
    "    train_auc = auc(fpr, tpr) # AUC\n",
    "        \n",
    "    # Find and store accuracy, F1, and AUC of the 3 models from previous line on test set\n",
    "    test_accuracy = clf_accuracy.score(X_test, Y_test)  # Accuracy\n",
    "    \n",
    "    test_F1 = f1_score(Y_test, clf_F1.predict(X_test))   # F1\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, clf_AUC.predict_proba(X_test)[:,1])\n",
    "    test_auc = auc(false_positive_rate, true_positive_rate) # AUC\n",
    "\n",
    "    return train_accuracy, train_F1, train_auc, test_accuracy, test_F1, test_auc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8124, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0  1  2  3  4  5  6  7  8  9   ... 13 14 15 16 17 18 19 20 21 22\n",
       "0  p  x  s  n  t  p  f  c  n  k  ...  s  w  w  p  w  o  p  k  s  u\n",
       "1  e  x  s  y  t  a  f  c  b  k  ...  s  w  w  p  w  o  p  n  n  g\n",
       "2  e  b  s  w  t  l  f  c  b  n  ...  s  w  w  p  w  o  p  n  n  m\n",
       "3  p  x  y  w  t  p  f  c  n  n  ...  s  w  w  p  w  o  p  k  s  u\n",
       "4  e  x  s  g  f  n  f  w  b  k  ...  s  w  w  p  w  o  e  n  a  g\n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data', \n",
    "                    header=None)\n",
    "print(data.shape)\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "rows_to_drop = data[data.isnull().any(axis=1)] \n",
    "print(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_b</th>\n",
       "      <th>1_c</th>\n",
       "      <th>1_f</th>\n",
       "      <th>1_k</th>\n",
       "      <th>1_s</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_f</th>\n",
       "      <th>2_g</th>\n",
       "      <th>2_s</th>\n",
       "      <th>2_y</th>\n",
       "      <th>...</th>\n",
       "      <th>21_s</th>\n",
       "      <th>21_v</th>\n",
       "      <th>21_y</th>\n",
       "      <th>22_d</th>\n",
       "      <th>22_g</th>\n",
       "      <th>22_l</th>\n",
       "      <th>22_m</th>\n",
       "      <th>22_p</th>\n",
       "      <th>22_u</th>\n",
       "      <th>22_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1_b  1_c  1_f  1_k  1_s  1_x  2_f  2_g  2_s  2_y  ...  21_s  21_v  21_y  \\\n",
       "0    0    0    0    0    0    1    0    0    1    0  ...     1     0     0   \n",
       "1    0    0    0    0    0    1    0    0    1    0  ...     0     0     0   \n",
       "2    1    0    0    0    0    0    0    0    1    0  ...     0     0     0   \n",
       "3    0    0    0    0    0    1    0    0    0    1  ...     1     0     0   \n",
       "4    0    0    0    0    0    1    0    0    1    0  ...     0     0     0   \n",
       "\n",
       "   22_d  22_g  22_l  22_m  22_p  22_u  22_w  \n",
       "0     0     0     0     0     0     1     0  \n",
       "1     0     1     0     0     0     0     0  \n",
       "2     0     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     1     0  \n",
       "4     0     1     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Labels\n",
    "y = data[0]\n",
    "\n",
    "Y=[] \n",
    "for i in y:\n",
    "    if i == \"e\":\n",
    "        Y += [1]\n",
    "    else:\n",
    "        Y += [-1]\n",
    "\n",
    "\n",
    "# Ectract Data\n",
    "d = data.loc[:, 1:54]\n",
    "\n",
    "# One hot encode categorical data\n",
    "X = pd.DataFrame(pd.get_dummies(d))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8124, 23)\n",
      "e    4208\n",
      "p    3916\n",
      "Name: 0, dtype: int64\n",
      "0.517971442639094\n"
     ]
    }
   ],
   "source": [
    "# %POZ\n",
    "print(data.shape)\n",
    "print(y.value_counts())\n",
    "\n",
    "percent_positive = 4208/8124\n",
    "print(percent_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running 5 trials across the three algos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:   35.2s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 26.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:   30.5s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 24.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:   27.9s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   47.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 94.6min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 105.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:   39.9s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 363.4min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 434.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:   28.8s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   59.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 27.3min finished\n"
     ]
    }
   ],
   "source": [
    "log_reg_data = []\n",
    "rf_data = []\n",
    "knn_data = []\n",
    "\n",
    "for i in range(5):\n",
    "    #split data for training and testing\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=5000)\n",
    "\n",
    "    log_reg_data += log_reg_classifier(X_train, Y_train, X_test, Y_test)\n",
    "    rf_data += rf_classifier(X_train,Y_train, X_test, Y_test)\n",
    "    knn_data += knn_classifier(X_train,Y_train, X_test, Y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ACC</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test ACC</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR Mush Trial 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR Mush Trial 2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR Mush Trial 3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR Mush Trial 4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR Mush Trial 5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Train ACC  Train F1  Train AUC  Test ACC  Test F1  Test AUC\n",
       "LR Mush Trial 1        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "LR Mush Trial 2        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "LR Mush Trial 3        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "LR Mush Trial 4        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "LR Mush Trial 5        1.0       1.0        1.0       1.0      1.0       1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ACC    1.0\n",
      "Train F1     1.0\n",
      "Train AUC    1.0\n",
      "Test ACC     1.0\n",
      "Test F1      1.0\n",
      "Test AUC     1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Random Forest Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ACC</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test ACC</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF Mush Trial 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Mush Trial 2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Mush Trial 3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Mush Trial 4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Mush Trial 5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Train ACC  Train F1  Train AUC  Test ACC  Test F1  Test AUC\n",
       "RF Mush Trial 1        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "RF Mush Trial 2        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "RF Mush Trial 3        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "RF Mush Trial 4        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "RF Mush Trial 5        1.0       1.0        1.0       1.0      1.0       1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ACC    1.0\n",
      "Train F1     1.0\n",
      "Train AUC    1.0\n",
      "Test ACC     1.0\n",
      "Test F1      1.0\n",
      "Test AUC     1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "KNN Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ACC</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test ACC</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN Mush Trial 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Mush Trial 2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Mush Trial 3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Mush Trial 4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Mush Trial 5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train ACC  Train F1  Train AUC  Test ACC  Test F1  Test AUC\n",
       "KNN Mush Trial 1        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "KNN Mush Trial 2        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "KNN Mush Trial 3        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "KNN Mush Trial 4        1.0       1.0        1.0       1.0      1.0       1.0\n",
       "KNN Mush Trial 5        1.0       1.0        1.0       1.0      1.0       1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ACC    1.0\n",
      "Train F1     1.0\n",
      "Train AUC    1.0\n",
      "Test ACC     1.0\n",
      "Test F1      1.0\n",
      "Test AUC     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Results\n",
    "df_log_reg = pd.DataFrame(columns=('Train ACC', 'Train F1','Train AUC', 'Test ACC', 'Test F1', 'Test AUC'))\n",
    "df_log_reg.loc['LR Mush Trial 1'] = log_reg_data[0:6]\n",
    "df_log_reg.loc['LR Mush Trial 2'] = log_reg_data[6:12]\n",
    "df_log_reg.loc['LR Mush Trial 3'] = log_reg_data[12:18]\n",
    "df_log_reg.loc['LR Mush Trial 4'] = log_reg_data[18:24]\n",
    "df_log_reg.loc['LR Mush Trial 5'] = log_reg_data[24:32]\n",
    "\n",
    "#Random Forest Results\n",
    "df_rf = pd.DataFrame(columns=('Train ACC', 'Train F1','Train AUC', 'Test ACC', 'Test F1', 'Test AUC'))\n",
    "df_rf.loc['RF Mush Trial 1'] = rf_data[0:6]\n",
    "df_rf.loc['RF Mush Trial 2'] = rf_data[6:12]\n",
    "df_rf.loc['RF Mush Trial 3'] = rf_data[12:18]\n",
    "df_rf.loc['RF Mush Trial 4'] = rf_data[18:24]\n",
    "df_rf.loc['RF Mush Trial 5'] = rf_data[24:32]\n",
    "\n",
    "\n",
    "#KNN Results\n",
    "df_knn = pd.DataFrame(columns=('Train ACC', 'Train F1','Train AUC', 'Test ACC', 'Test F1', 'Test AUC'))\n",
    "df_knn.loc['KNN Mush Trial 1'] = knn_data[0:6]\n",
    "df_knn.loc['KNN Mush Trial 2'] = knn_data[6:12]\n",
    "df_knn.loc['KNN Mush Trial 3'] = knn_data[12:18]\n",
    "df_knn.loc['KNN Mush Trial 4'] = knn_data[18:24]\n",
    "df_knn.loc['KNN Mush Trial 5'] = knn_data[24:32]\n",
    "\n",
    "print('Logistic Regression Results')\n",
    "display(df_log_reg)\n",
    "print(df_log_reg.mean())\n",
    "\n",
    "print('\\n\\nRandom Forest Results')\n",
    "display(df_rf)\n",
    "print(df_rf.mean())\n",
    "\n",
    "print('\\n\\nKNN Results')\n",
    "display(df_knn)\n",
    "print(df_knn.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to save the data for ttests\n",
    "df_log_reg.to_csv(\"lr_mush.csv\")\n",
    "df_rf.to_csv(\"rf_mush.csv\")\n",
    "df_knn.to_csv(\"knn_mush.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
