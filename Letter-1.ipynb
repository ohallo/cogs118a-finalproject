{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LETTER-1\n",
    "##  (\"O\" positive class)\n",
    "### Source:\n",
    "https://archive.ics.uci.edu/ml/datasets/Letter+Recognition\n",
    "### Goal: \n",
    "Identify black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests, zipfile, io\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, roc_auc_score, roc_curve, make_scorer\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo 1: LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_classifier(X_train, Y_train, X_test, Y_test):\n",
    "    # define hyperparameters to search through & error metrics \n",
    "    C_list = [10**-8,10**-7,10**-6,10**-5,10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3,10**4]\n",
    "    penalty_list = ['l2', 'l1', 'none']\n",
    "    solver = ['saga'] #this solver works for no penalty, l1 and l2 penalties\n",
    "    scoring = {'Accuracy': make_scorer(accuracy_score), 'f1': 'f1', 'AUC': 'roc_auc'}\n",
    "    classifier = LogisticRegression()\n",
    "        \n",
    "    # gridsearch \n",
    "    lr =  GridSearchCV(classifier, {'C':C_list, 'penalty':penalty_list,'solver':solver},\n",
    "                                   scoring=scoring,refit=False, cv=5, n_jobs=-1, \n",
    "                                   return_train_score=True, verbose=2 ) \n",
    "        \n",
    "    lr.fit(X_train,Y_train)\n",
    "    results = pd.DataFrame(lr.cv_results_)\n",
    "        \n",
    "    # Get each parameter settings that gives best accuracy, F1, and AUC on validation set\n",
    "    best_AUC = results[results['rank_test_AUC']==1]['params'].values[0]\n",
    "    best_accuracy = results[results['rank_test_Accuracy']  ==1]['params'].values[0]\n",
    "    best_F1 = results[results['rank_test_f1']  ==1]['params'].values[0]\n",
    "        \n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    clf_AUC = LogisticRegression(C=best_AUC['C'], solver = best_AUC['solver'],\n",
    "                             penalty=best_AUC['penalty']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_accuracy = LogisticRegression(C=best_accuracy['C'], solver = best_accuracy['solver'],\n",
    "                             penalty=best_accuracy['penalty']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_F1 = LogisticRegression(C=best_F1['C'], solver = best_F1['solver'],\n",
    "                                penalty=best_F1['penalty']).fit(X_train, Y_train)\n",
    "        \n",
    "    # For average training performance\n",
    "    train_accuracy = clf_accuracy.score(X_train, Y_train)  # Accuracy  \n",
    "    train_F1 = f1_score(Y_train, clf_F1.predict(X_train))   # F1\n",
    "    fpr, tpr, threshold = roc_curve(Y_train, clf_AUC.predict_proba(X_train)[:,1])\n",
    "    train_auc = auc(fpr, tpr) # AUC\n",
    "        \n",
    "    # Find and store accuracy, F1, and AUC of the 3 models from previous line on test set\n",
    "    test_accuracy = clf_accuracy.score(X_test, Y_test)  # Accuracy\n",
    "    \n",
    "    test_F1 = f1_score(Y_test, clf_F1.predict(X_test))   # F1\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, clf_AUC.predict_proba(X_test)[:,1])\n",
    "    test_auc = auc(false_positive_rate, true_positive_rate) # AUC\n",
    "\n",
    "    return train_accuracy, train_F1, train_auc, test_accuracy, test_F1, test_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo 2: RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classifier(X_train,Y_train,X_test,Y_test):\n",
    "    # define hyperparameters to search through & error metrics  \n",
    "    n_estimators = [1024]\n",
    "    min_samples_split = [1,2,4,6,8,12,16,20]\n",
    "    scoring = {'Accuracy': make_scorer(accuracy_score), 'f1': 'f1', 'AUC': 'roc_auc'}\n",
    "    classifier = RandomForestClassifier()\n",
    "\n",
    "    rf =  GridSearchCV(classifier, {'n_estimators':n_estimators, 'min_samples_split':min_samples_split},\n",
    "                                   scoring=scoring,refit=False, cv=5, n_jobs=-1, \n",
    "                                   return_train_score=True, verbose=2) \n",
    "\n",
    "    rf.fit(X_train,Y_train)\n",
    "    results = pd.DataFrame(rf.cv_results_)\n",
    "        \n",
    "    # Get each parameter settings that gives best accuracy, F1, and AUC on validation set\n",
    "    best_AUC = results[results['rank_test_AUC']==1]['params'].values[0]\n",
    "    best_accuracy = results[results['rank_test_Accuracy']  ==1]['params'].values[0]\n",
    "    best_F1 = results[results['rank_test_f1']  ==1]['params'].values[0]\n",
    "\n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    clf_AUC = RandomForestClassifier(n_estimators=best_AUC['n_estimators'], \n",
    "                              min_samples_split=best_AUC['min_samples_split']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_accuracy = RandomForestClassifier(n_estimators=best_accuracy['n_estimators'], \n",
    "                              min_samples_split=best_accuracy['min_samples_split']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_F1 = RandomForestClassifier(n_estimators=best_F1['n_estimators'], \n",
    "                                  min_samples_split=best_F1['min_samples_split']).fit(X_train, Y_train)\n",
    "\n",
    "    # For average training performance\n",
    "    train_accuracy = clf_accuracy.score(X_train, Y_train)  # Accuracy  \n",
    "    train_F1 = f1_score(Y_train, clf_F1.predict(X_train))   # F1\n",
    "    fpr, tpr, threshold = roc_curve(Y_train, clf_AUC.predict_proba(X_train)[:,1])\n",
    "    train_auc = auc(fpr, tpr) # AUC\n",
    "        \n",
    "    # Find and store accuracy, F1, and AUC of the 3 models from previous line on test set\n",
    "    test_accuracy = clf_accuracy.score(X_test, Y_test)  # Accuracy\n",
    "    \n",
    "    test_F1 = f1_score(Y_test, clf_F1.predict(X_test))   # F1\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, clf_AUC.predict_proba(X_test)[:,1])\n",
    "    test_auc = auc(false_positive_rate, true_positive_rate) # AUC\n",
    "\n",
    "    return train_accuracy, train_F1, train_auc, test_accuracy, test_F1, test_auc\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo 3: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(X_train,Y_train,X_test,Y_test):\n",
    "    # define hyperparameters to search through & error metrics  \n",
    "    n_neighbors = np.linspace(1, 105, num=27, dtype=int)\n",
    "    weights = ['uniform', 'distance']\n",
    "    p = [1,2]\n",
    "    scoring = {'Accuracy': make_scorer(accuracy_score), 'f1': 'f1', 'AUC': 'roc_auc'}\n",
    "    classifier = KNeighborsClassifier()\n",
    "\n",
    "    rf =  GridSearchCV(classifier, {'n_neighbors':n_neighbors, 'weights': weights, 'p':p},\n",
    "                                   scoring=scoring,refit=False, cv=5, n_jobs=-1, \n",
    "                                   return_train_score=True, verbose=2) \n",
    "\n",
    "    rf.fit(X_train,Y_train)\n",
    "    results = pd.DataFrame(rf.cv_results_)\n",
    "        \n",
    "    # Get each parameter settings that gives best accuracy, F1, and AUC on validation set\n",
    "    best_AUC = results[results['rank_test_AUC']==1]['params'].values[0]\n",
    "    best_accuracy = results[results['rank_test_Accuracy']  ==1]['params'].values[0]\n",
    "    best_F1 = results[results['rank_test_f1']  ==1]['params'].values[0]\n",
    "\n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    clf_AUC = KNeighborsClassifier(n_neighbors=best_AUC['n_neighbors'], \n",
    "                             weights=best_AUC['weights'], p = best_AUC['p']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_accuracy = KNeighborsClassifier(n_neighbors=best_accuracy['n_neighbors'], \n",
    "                              weights=best_accuracy['weights']).fit(X_train, Y_train)\n",
    "\n",
    "    clf_F1 = KNeighborsClassifier(n_neighbors=best_F1['n_neighbors'], \n",
    "                                  weights=best_F1['weights'], p = best_F1['p']).fit(X_train, Y_train)\n",
    "\n",
    "    # For average training performance\n",
    "    train_accuracy = clf_accuracy.score(X_train, Y_train)  # Accuracy  \n",
    "    train_F1 = f1_score(Y_train, clf_F1.predict(X_train))   # F1\n",
    "    fpr, tpr, threshold = roc_curve(Y_train, clf_AUC.predict_proba(X_train)[:,1])\n",
    "    train_auc = auc(fpr, tpr) # AUC\n",
    "        \n",
    "    # Find and store accuracy, F1, and AUC of the 3 models from previous line on test set\n",
    "    test_accuracy = clf_accuracy.score(X_test, Y_test)  # Accuracy\n",
    "    \n",
    "    test_F1 = f1_score(Y_test, clf_F1.predict(X_test))   # F1\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, clf_AUC.predict_proba(X_test)[:,1])\n",
    "    test_auc = auc(false_positive_rate, true_positive_rate) # AUC\n",
    "\n",
    "    return train_accuracy, train_F1, train_auc, test_accuracy, test_F1, test_auc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16\n",
       "0  T   2   8   3   5   1   8  13   0   6   6  10   8   0   8   0   8\n",
       "1  I   5  12   3   7   2  10   5   5   4  13   3   9   2   8   4  10\n",
       "2  D   4  11   6   8   6  10   6   2   6  10   3   7   3   7   3   9\n",
       "3  N   7  11   6   6   3   5   9   4   6   4   4  10   6  10   2   8\n",
       "4  G   2   1   3   1   1   8   6   6   6   6   5   9   1   7   5  10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data', header=None)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#checking if any observations have missing data\n",
    "rows_to_drop = data[data.isnull().any(axis=1)] \n",
    "print(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get inputs (X) & targets (y) \n",
    "X = data.loc[: , 1:16] #feature inputs: taking colums \"1\" to \"16\"\n",
    "labels = data[0]\n",
    "\n",
    "\n",
    "#transform\n",
    "\n",
    "#determining +/- classes, O = positive class, everything else = negative class\n",
    "Y=[]\n",
    "for i in labels:\n",
    "    if i in ('O'):\n",
    "        Y += [1]\n",
    "    else:\n",
    "        Y += [-1]\n",
    "        \n",
    "data['y'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    19247\n",
      " 1      753\n",
      "Name: y, dtype: int64\n",
      "0.03765\n"
     ]
    }
   ],
   "source": [
    "# %POZ\n",
    "print(data['y'].value_counts())\n",
    "\n",
    "percent_positive = 753/20000\n",
    "print(percent_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Trials across the three algos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:   10.0s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 11.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:   11.6s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 11.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:    9.8s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 11.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:    9.8s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 39 candidates, totalling 195 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 195 out of 195 | elapsed:    8.9s finished\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/annaleaohalloran/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 11.4min finished\n"
     ]
    }
   ],
   "source": [
    "log_reg_data = []\n",
    "rf_data = []\n",
    "knn_data = []\n",
    "\n",
    "for i in range(5):\n",
    "    #split data for training and testing\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=5000)\n",
    "\n",
    "        \n",
    "    #tansform data for Logistic Regression and KNN\n",
    "    X_train_t = StandardScaler().fit_transform(X_train)    \n",
    "    X_test_t = StandardScaler().fit_transform(X_test)\n",
    "    \n",
    "    log_reg_data += log_reg_classifier(X_train_t, Y_train, X_test_t, Y_test)\n",
    "    rf_data += rf_classifier(X_train,Y_train, X_test, Y_test)\n",
    "    knn_data += knn_classifier(X_train_t,Y_train, X_test_t, Y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ACC</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test ACC</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR Letter 1 Trial 1</th>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875447</td>\n",
       "      <td>0.962533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR Letter 1 Trial 2</th>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858784</td>\n",
       "      <td>0.962533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.846642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR Letter 1 Trial 3</th>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864379</td>\n",
       "      <td>0.962067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR Letter 1 Trial 4</th>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866015</td>\n",
       "      <td>0.962200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR Letter 1 Trial 5</th>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863934</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.844450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Train ACC  Train F1  Train AUC  Test ACC  Test F1  \\\n",
       "LR Letter 1 Trial 1     0.9618       0.0   0.875447  0.962533      0.0   \n",
       "LR Letter 1 Trial 2     0.9618       0.0   0.858784  0.962533      0.0   \n",
       "LR Letter 1 Trial 3     0.9632       0.0   0.864379  0.962067      0.0   \n",
       "LR Letter 1 Trial 4     0.9628       0.0   0.866015  0.962200      0.0   \n",
       "LR Letter 1 Trial 5     0.9624       0.0   0.863934  0.962333      0.0   \n",
       "\n",
       "                     Test AUC  \n",
       "LR Letter 1 Trial 1  0.866262  \n",
       "LR Letter 1 Trial 2  0.846642  \n",
       "LR Letter 1 Trial 3  0.858188  \n",
       "LR Letter 1 Trial 4  0.853746  \n",
       "LR Letter 1 Trial 5  0.844450  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ACC    0.962400\n",
      "Train F1     0.000000\n",
      "Train AUC    0.865712\n",
      "Test ACC     0.962333\n",
      "Test F1      0.000000\n",
      "Test AUC     0.853858\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Random Forest Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ACC</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test ACC</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF Letter 1 Trial 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988067</td>\n",
       "      <td>0.809573</td>\n",
       "      <td>0.997058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Letter 1 Trial 2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988467</td>\n",
       "      <td>0.830491</td>\n",
       "      <td>0.997183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Letter 1 Trial 3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986867</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.997514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Letter 1 Trial 4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986867</td>\n",
       "      <td>0.792492</td>\n",
       "      <td>0.996502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF Letter 1 Trial 5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987133</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.996441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Train ACC  Train F1  Train AUC  Test ACC   Test F1  \\\n",
       "RF Letter 1 Trial 1        1.0  1.000000        1.0  0.988067  0.809573   \n",
       "RF Letter 1 Trial 2        1.0  1.000000        1.0  0.988467  0.830491   \n",
       "RF Letter 1 Trial 3        1.0  0.994536        1.0  0.986867  0.797101   \n",
       "RF Letter 1 Trial 4        1.0  1.000000        1.0  0.986867  0.792492   \n",
       "RF Letter 1 Trial 5        1.0  1.000000        1.0  0.987133  0.795812   \n",
       "\n",
       "                     Test AUC  \n",
       "RF Letter 1 Trial 1  0.997058  \n",
       "RF Letter 1 Trial 2  0.997183  \n",
       "RF Letter 1 Trial 3  0.997514  \n",
       "RF Letter 1 Trial 4  0.996502  \n",
       "RF Letter 1 Trial 5  0.996441  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ACC    1.000000\n",
      "Train F1     0.998907\n",
      "Train AUC    1.000000\n",
      "Test ACC     0.987480\n",
      "Test F1      0.805094\n",
      "Test AUC     0.996940\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "KNN Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ACC</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test ACC</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN Letter 1 Trial 1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991400</td>\n",
       "      <td>0.887728</td>\n",
       "      <td>0.995656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Letter 1 Trial 2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>0.855184</td>\n",
       "      <td>0.993553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Letter 1 Trial 3</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988733</td>\n",
       "      <td>0.849778</td>\n",
       "      <td>0.996428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Letter 1 Trial 4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991467</td>\n",
       "      <td>0.900804</td>\n",
       "      <td>0.996031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Letter 1 Trial 5</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990400</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.992319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Train ACC  Train F1  Train AUC  Test ACC   Test F1  \\\n",
       "KNN Letter 1 Trial 1      1.000  1.000000        1.0  0.991400  0.887728   \n",
       "KNN Letter 1 Trial 2      1.000  1.000000        1.0  0.990200  0.855184   \n",
       "KNN Letter 1 Trial 3      0.996  0.945652        1.0  0.988733  0.849778   \n",
       "KNN Letter 1 Trial 4      1.000  1.000000        1.0  0.991467  0.900804   \n",
       "KNN Letter 1 Trial 5      1.000  1.000000        1.0  0.990400  0.871429   \n",
       "\n",
       "                      Test AUC  \n",
       "KNN Letter 1 Trial 1  0.995656  \n",
       "KNN Letter 1 Trial 2  0.993553  \n",
       "KNN Letter 1 Trial 3  0.996428  \n",
       "KNN Letter 1 Trial 4  0.996031  \n",
       "KNN Letter 1 Trial 5  0.992319  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ACC    0.999200\n",
      "Train F1     0.989130\n",
      "Train AUC    1.000000\n",
      "Test ACC     0.990440\n",
      "Test F1      0.872985\n",
      "Test AUC     0.994797\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Results\n",
    "df_log_reg = pd.DataFrame(columns=('Train ACC', 'Train F1','Train AUC', 'Test ACC', 'Test F1', 'Test AUC'))\n",
    "df_log_reg.loc['LR Letter 1 Trial 1'] = log_reg_data[0:6]\n",
    "df_log_reg.loc['LR Letter 1 Trial 2'] = log_reg_data[6:12]\n",
    "df_log_reg.loc['LR Letter 1 Trial 3'] = log_reg_data[12:18]\n",
    "df_log_reg.loc['LR Letter 1 Trial 4'] = log_reg_data[18:24]\n",
    "df_log_reg.loc['LR Letter 1 Trial 5'] = log_reg_data[24:32]\n",
    "\n",
    "#Random Forest Results\n",
    "df_rf = pd.DataFrame(columns=('Train ACC', 'Train F1','Train AUC', 'Test ACC', 'Test F1', 'Test AUC'))\n",
    "df_rf.loc['RF Letter 1 Trial 1'] = rf_data[0:6]\n",
    "df_rf.loc['RF Letter 1 Trial 2'] = rf_data[6:12]\n",
    "df_rf.loc['RF Letter 1 Trial 3'] = rf_data[12:18]\n",
    "df_rf.loc['RF Letter 1 Trial 4'] = rf_data[18:24]\n",
    "df_rf.loc['RF Letter 1 Trial 5'] = rf_data[24:32]\n",
    "\n",
    "\n",
    "#KNN Results\n",
    "df_knn = pd.DataFrame(columns=('Train ACC', 'Train F1','Train AUC', 'Test ACC', 'Test F1', 'Test AUC'))\n",
    "df_knn.loc['KNN Letter 1 Trial 1'] = knn_data[0:6]\n",
    "df_knn.loc['KNN Letter 1 Trial 2'] = knn_data[6:12]\n",
    "df_knn.loc['KNN Letter 1 Trial 3'] = knn_data[12:18]\n",
    "df_knn.loc['KNN Letter 1 Trial 4'] = knn_data[18:24]\n",
    "df_knn.loc['KNN Letter 1 Trial 5'] = knn_data[24:32]\n",
    "\n",
    "print('Logistic Regression Results')\n",
    "display(df_log_reg)\n",
    "print(df_log_reg.mean())\n",
    "\n",
    "print('\\n\\nRandom Forest Results')\n",
    "display(df_rf)\n",
    "print(df_rf.mean())\n",
    "\n",
    "print('\\n\\nKNN Results')\n",
    "display(df_knn)\n",
    "print(df_knn.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to save the data for ttests\n",
    "df_log_reg.to_csv(\"lr_letter1.csv\")\n",
    "df_rf.to_csv(\"rf_letter1.csv\")\n",
    "df_knn.to_csv(\"knn_letter1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
